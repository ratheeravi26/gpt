import os
import json
from azure.common.credentials import ServicePrincipalCredentials
from azure.mgmt.resource import ResourceManagementClient
from azure.mgmt.datafactory import DataFactoryManagementClient

# Set the credentials and subscription ID
tenant_id = os.environ.get('AZURE_TENANT_ID')
client_id = os.environ.get('AZURE_CLIENT_ID')
client_secret = os.environ.get('AZURE_CLIENT_SECRET')
subscription_id = os.environ.get('AZURE_SUBSCRIPTION_ID')

# Set the resource group name and ADF instance name
resource_group_name = 'my_resource_group'
adf_name = 'my_adf_instance'

# Set the paths to the old and new ARM templates
old_template_path = 'old/arm_template.json'
new_template_path = 'new/arm_template.json'

# Set up the credentials and clients
credentials = ServicePrincipalCredentials(client_id=client_id, secret=client_secret, tenant=tenant_id)
resource_client = ResourceManagementClient(credentials, subscription_id)
adf_client = DataFactoryManagementClient(credentials, subscription_id)

# Get the list of objects in the ADF instance
objects = adf_client.factories.list_objects(resource_group_name, adf_name)

# Load the old and new ARM templates
with open(old_template_path, 'r') as f:
    old_template = json.load(f)

with open(new_template_path, 'r') as f:
    new_template = json.load(f)

# Function to recursively find the top-level pipelines
def find_top_level_pipelines(dependencies, top_level_pipelines):
    for dependency in dependencies:
        if dependency not in top_level_pipelines:
            top_level_pipelines.append(dependency)
            if dependency in deleted_objects:
                find_top_level_pipelines(deleted_objects[dependency], top_level_pipelines)

# Identify the objects that were deleted
deleted_objects = {}
for obj in objects:
    obj_id = obj.id
    obj_name = obj.name
    obj_type = obj.type
    if obj_type not in ['datasets', 'linkedServices', 'pipelines']:
        continue
    if obj_id not in new_template['resources']:
        # Check if the deleted object is a pipeline
        if obj_type == 'pipelines':
            # Check if the deleted pipeline has top-level dependencies
            dependencies = adf_client.pipelines.get(resource_group_name, adf_name, obj_name).properties.dependencies
            if dependencies and any(dep.depends_on_pipeline for dep in dependencies):
                # Retrieve the names of top-level dependent pipelines
                top_level_dependencies = {dep.depends_on_pipeline: {} for dep in dependencies if dep.depends_on_pipeline}
                deleted_objects[obj_name] = top_level_dependencies
            else:
                deleted_objects[obj_name] = {}
        else:
            deleted_objects[obj_name] = {}

# Find all the top-level pipelines
top_level_pipelines = []
for deleted_object in deleted_objects:
    find_top_level_pipelines(deleted_objects[deleted_object], top_level_pipelines)

# Function to recursively print the pipeline tree
def print_pipeline_tree(pipeline_name, dependencies, indent=0):
    print(' ' * indent + '- ' + pipeline_name)
    for dependency in dependencies:
        print_pipeline_tree(dependency, dependencies[dependency], indent + 2)

# Print the pipeline tree for each top-level pipeline
for pipeline in top_level_pipelines:
    print_pipeline_tree(pipeline, deleted
